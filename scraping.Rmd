---
title: "Scraping wikisource"
author: "Thomas"
date: "7/12/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages
```{r}
library(rvest)
library(tidyverse)
library(stringr)
```


Getting the links
```{r}
# set webpage 
page <- read_html("https://zh.wikisource.org/wiki/%E6%A2%81%E6%9B%B8")

link <- page %>%
  html_nodes("ul>li>a") %>%
  html_attr('href') 

#link

link_check <- link[1:56] %>% #subset for wich ones I need
  str_replace_all("/(wiki.+)", "https://zh.wikisource.org/\\1") #add wikisource.org

#link_check


```

Scraping the webpages
```{r echo = FALSE}
teksten <- map_df(link_check, #use purrr map_df to get all in 1 df
                function(url){
                  p_url <- url %>% #grab all <p>
                    read_html() %>%
                    html_nodes(xpath='//*[@id="mw-content-text"]/div/p') %>%
                    html_text() %>%
                    as.data.frame()

                  
                  dl_url <- url %>% #grab all <dl>
                    read_html() %>%
                    html_nodes(xpath='//*[@id="mw-content-text"]/div/dl') %>%
                    html_text()  %>%
                    as.data.frame()
                  
                  return(full_join(p_url, dl_url))
                })
#View(teksten)
```

Write in a document

```{r}
write.table(teksten, "/Users/Thomas/Desktop/liangshu.txt") #change name
```















